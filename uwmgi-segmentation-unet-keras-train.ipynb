{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"In this notebook, we perform **GI tract semantic image segmentation** using U-Net. ","metadata":{}},{"cell_type":"markdown","source":"**Libraries**","metadata":{}},{"cell_type":"code","source":"# Core\nimport pandas as pd\nimport numpy as np\nimport os\nimport cv2\nimport gc\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm\nfrom datetime import datetime\nimport json,itertools\nfrom typing import Optional\nfrom glob import glob\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.gridspec as gridspec\nimport matplotlib.patches as mpatches\nimport matplotlib as mpl\nfrom sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\nimport random\n\n# Keras\nfrom tensorflow import keras\nimport tensorflow as tf\nimport keras\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.losses import binary_crossentropy\nfrom keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\nfrom keras.models import load_model, save_model","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reproducibility**","metadata":{}},{"cell_type":"code","source":"# Set random seeds\ndef set_seed(seed=0):\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\nset_seed()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Config**","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 16\nEPOCHS = 40\nn_splits = 5\nfold_selected = 2   # 1,...,5\nim_width = 320\nim_height = 320","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"markdown","source":"**Train set**","metadata":{}},{"cell_type":"code","source":"# Train set\ntrain_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')\nprint(train_df.shape)\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Test set**","metadata":{}},{"cell_type":"markdown","source":"*Note:* This is a code competition, which means the 'real' test set will be populated at inference time.","metadata":{}},{"cell_type":"code","source":"# Test set\ntest_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\n\nif len(test_df)==0:\n    DEBUG=True\n    test_df = train_df.iloc[:10*16*3,:]\n    test_df[\"segmentation\"]=''\n    test_df=test_df.rename(columns={\"segmentation\":\"predicted\"})\nelse:\n    DEBUG=False\n\nsubmission=test_df.copy()\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"**Metadata**","metadata":{}},{"cell_type":"code","source":"# Metadata\ndef preprocessing(df, subset=\"train\"):\n    #--------------------------------------------------------------------------\n    df[\"case\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\")[0].replace(\"case\", \"\")))\n    df[\"day\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\")[1].replace(\"day\", \"\")))\n    df[\"slice\"] = df[\"id\"].apply(lambda x: x.split(\"_\")[3])\n    #--------------------------------------------------------------------------\n    if (subset==\"train\") or (DEBUG):\n        DIR=\"../input/uw-madison-gi-tract-image-segmentation/train\"\n    else:\n        DIR=\"../input/uw-madison-gi-tract-image-segmentation/test\"\n    \n    all_images = glob(os.path.join(DIR, \"**\", \"*.png\"), recursive=True)\n    x = all_images[0].rsplit(\"/\", 4)[0] ## ../input/uw-madison-gi-tract-image-segmentation/train\n\n    path_partial_list = []\n    for i in range(0, df.shape[0]):\n        path_partial_list.append(os.path.join(x,\n                              \"case\"+str(df[\"case\"].values[i]),\n                              \"case\"+str(df[\"case\"].values[i])+\"_\"+ \"day\"+str(df[\"day\"].values[i]),\n                              \"scans\",\n                              \"slice_\"+str(df[\"slice\"].values[i])))\n    df[\"path_partial\"] = path_partial_list\n    #--------------------------------------------------------------------------\n    path_partial_list = []\n    for i in range(0, len(all_images)):\n        path_partial_list.append(str(all_images[i].rsplit(\"_\",4)[0]))\n\n    tmp_df = pd.DataFrame()\n    tmp_df['path_partial'] = path_partial_list\n    tmp_df['path'] = all_images\n\n    #--------------------------------------------------------------------------\n    df = df.merge(tmp_df, on=\"path_partial\").drop(columns=[\"path_partial\"])\n    #--------------------------------------------------------------------------\n    df[\"width\"] = df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[1]))\n    df[\"height\"] = df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[2]))\n    #--------------------------------------------------------------------------\n    del x, path_partial_list, tmp_df\n    #--------------------------------------------------------------------------\n    \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = preprocessing(train_df, subset=\"train\")\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df=preprocessing(test_df, subset=\"test\")\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Restructure df**","metadata":{}},{"cell_type":"code","source":"# Restructure\ndef restructure(df, subset=\"train\"):\n    # RESTRUCTURE  DATAFRAME\n    df_out = pd.DataFrame({'id': df['id'][::3]})\n\n    if subset==\"train\":\n        df_out['large_bowel'] = df['segmentation'][::3].values\n        df_out['small_bowel'] = df['segmentation'][1::3].values\n        df_out['stomach'] = df['segmentation'][2::3].values\n\n    df_out['path'] = df['path'][::3].values\n    df_out['case'] = df['case'][::3].values\n    df_out['day'] = df['day'][::3].values\n    df_out['slice'] = df['slice'][::3].values\n    df_out['width'] = df['width'][::3].values\n    df_out['height'] = df['height'][::3].values\n\n    df_out=df_out.reset_index(drop=True)\n    df_out=df_out.fillna('')\n    if subset==\"train\":\n        df_out['count'] = np.sum(df_out.iloc[:,1:4]!='',axis=1).values\n    \n    return df_out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=restructure(train_df, subset=\"train\")\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df=restructure(test_df, subset=\"test\")\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Remove mislabelled data**","metadata":{}},{"cell_type":"code","source":"# Remove mislabeled training data\ntrain_df = train_df[(train_df['case']!=7)|(train_df['day']!=0)].reset_index(drop=True)\ntrain_df = train_df[(train_df['case']!=81)|(train_df['day']!=30)].reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Garbage collection\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions","metadata":{}},{"cell_type":"markdown","source":"**RLE encoding**","metadata":{}},{"cell_type":"code","source":"# Run-length encoding\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle_decode(mask_rle, shape, color=1):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros((shape[0] * shape[1], shape[2]), dtype=np.float32)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n    return img.reshape(shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Metrics**","metadata":{}},{"cell_type":"code","source":"# Metrics\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef iou_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n    return iou\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(tf.cast(y_true, tf.float32), y_pred) + dice_loss(tf.cast(y_true, tf.float32), y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data generator**","metadata":{}},{"cell_type":"code","source":"# Images reshaped to (im_height,im_width)\nclass DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, df, batch_size = BATCH_SIZE, subset=\"train\", shuffle=False):\n        super().__init__()\n        self.df = df\n        self.shuffle = shuffle\n        self.subset = subset\n        self.batch_size = batch_size\n        self.indexes = np.arange(len(df))\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.floor(len(self.df) / self.batch_size))\n    \n    def on_epoch_end(self):\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    def __getitem__(self, index):\n        X = np.empty((self.batch_size,im_height,im_width,3))\n        y = np.empty((self.batch_size,im_height,im_width,3))\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        for i, img_path in enumerate(self.df['path'].iloc[indexes]):\n            w=self.df['width'].iloc[indexes[i]]\n            h=self.df['height'].iloc[indexes[i]]\n            img = self.__load_grayscale(img_path)  # shape: (im_height,im_width,1)\n            X[i,] = img   # broadcast to shape: (im_height,im_width,3)\n            if self.subset == 'train':\n                for k,j in enumerate([\"large_bowel\",\"small_bowel\",\"stomach\"]):\n                    rles = self.df[j].iloc[indexes[i]]\n                    mask = rle_decode(rles, shape=(h, w, 1))\n                    mask = cv2.resize(mask, (im_height,im_width))\n                    y[i,:,:,k] = mask\n        if self.subset == 'train':\n            return X, y\n        else: \n            return X\n        \n        # To do: add data augmentation\n        \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)\n        dsize = (im_height,im_width)\n        img = cv2.resize(img, dsize)\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n        return img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"**Target distribution**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,4))\nbar = plt.bar([1,2,3],100*np.mean(train_df.iloc[:,1:4]!='',axis=0))\nplt.title('Percent Training Images with Mask', fontsize=16)\nplt.ylabel('Percent of Images'); plt.xlabel('Class Type')\nplt.xticks([1,2,3])\nlabels=[\"large bowel\",\"small bowel\",\"stomach\"]\nfor rect, lbl in zip(bar, labels):\n    height = rect.get_height()\n    plt.text(rect.get_x() + rect.get_width()/3, height,  lbl,\n             ha='center', va='bottom',fontsize=16)\n    plt.text(rect.get_x() + rect.get_width()/1.3, height, '%.1f %%' % height,\n             ha='center', va='bottom',fontsize=13)\n\nplt.ylim((0,50))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Preview some samples**","metadata":{}},{"cell_type":"code","source":"# SAMPLES\nMasks = list(train_df[train_df['large_bowel']!=''].sample(BATCH_SIZE).index)\nMasks += list(train_df[train_df['small_bowel']!=''].sample(BATCH_SIZE*2).index)\nMasks += list(train_df[train_df['stomach']!=''].sample(BATCH_SIZE*3).index)\n\n# DATA GENERATOR\nView_batches = DataGenerator(train_df[train_df.index.isin(Masks)],shuffle=True)\n\n# Visualizing\nfig = plt.figure(figsize=(10, 25))\ngs = gridspec.GridSpec(nrows=6, ncols=2)\ncolors = ['yellow','green','red']\nlabels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\npatches = [ mpatches.Patch(color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n\ncmap1 = mpl.colors.ListedColormap(colors[0])\ncmap2 = mpl.colors.ListedColormap(colors[1])\ncmap3= mpl.colors.ListedColormap(colors[2])\n\nfor i in range(6):\n    images, mask = View_batches[i]\n    sample_img=images[0,:,:,0]\n    mask1=mask[0,:,:,0]\n    mask2=mask[0,:,:,1]\n    mask3=mask[0,:,:,2]\n    \n    ax0 = fig.add_subplot(gs[i, 0])\n    im = ax0.imshow(sample_img, cmap='bone')\n\n    ax1 = fig.add_subplot(gs[i, 1])\n    if i==0:\n        ax0.set_title(\"Image\", fontsize=15, weight='bold', y=1.02)\n        ax1.set_title(\"Mask\", fontsize=15, weight='bold', y=1.02)\n        plt.legend(handles=patches, bbox_to_anchor=(1.1, 0.65), loc=2, borderaxespad=0.4,fontsize = 14,title='Mask Labels', title_fontsize=14, edgecolor=\"black\",  facecolor='#c5c6c7')\n\n    l0 = ax1.imshow(sample_img, cmap='bone')\n    l1 = ax1.imshow(np.ma.masked_where(mask1== False,  mask1),cmap=cmap1, alpha=1)\n    l2 = ax1.imshow(np.ma.masked_where(mask2== False,  mask2),cmap=cmap2, alpha=1)\n    l3 = ax1.imshow(np.ma.masked_where(mask3== False,  mask3),cmap=cmap3, alpha=1)\n    _ = [ax.set_axis_off() for ax in [ax0,ax1]]\n\n    colors = [im.cmap(im.norm(1)) for im in [l1,l2, l3]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross-validation","metadata":{}},{"cell_type":"markdown","source":"**Group k-fold**","metadata":{}},{"cell_type":"code","source":"# Group by case id\nskf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)\nfor fold, (_, val_idx) in enumerate(skf.split(X=train_df, y=train_df['count'], groups=train_df['case']), 1):\n    train_df.loc[val_idx, 'fold'] = fold\n\ntrain_df['fold'] = train_df['fold'].astype(np.uint8)\n\ntrain_ids = train_df[train_df[\"fold\"]!=fold_selected].index\nvalid_ids = train_df[train_df[\"fold\"]==fold_selected].index\n\nX_train = train_df[train_df.index.isin(train_ids)]\nX_valid = train_df[train_df.index.isin(valid_ids)]\n\ntrain_df.groupby('fold').size()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fold sizes\ntrain_df.groupby(['fold','count'])['id'].count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Debugging**","metadata":{}},{"cell_type":"code","source":"# Check submission format works\nexperimental=False\nif experimental:\n    X_train=X_train[X_train.case.isin(X_train.case.unique()[:5])]       # take first few cases\n    X_valid=X_valid[X_valid.case.isin(X_valid.case.unique()[:2])]       # take first few cases\n    \nprint('X_train shape:', X_train.shape)\nprint('X_valid shape:', X_valid.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Define generator**","metadata":{}},{"cell_type":"code","source":"train_generator = DataGenerator(X_train, shuffle=True)\nval_generator = DataGenerator(X_valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# U-Net model","metadata":{}},{"cell_type":"markdown","source":"**Download U-Net**","metadata":{}},{"cell_type":"code","source":"! pip install segmentation-models","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install git+https://github.com/qubvel/segmentation_models","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models as sm\nsm.set_framework('tf.keras')\nsm.framework()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Define model**","metadata":{}},{"cell_type":"code","source":"from segmentation_models import Unet\nfrom segmentation_models.utils import set_trainable\n\nmodel = Unet('resnet34',input_shape=(im_height, im_width, 3), classes=3, activation='sigmoid', encoder_weights='imagenet')\nmodel.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef,iou_coef])","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model summary\nmodel.summary()","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training model","metadata":{}},{"cell_type":"markdown","source":"**Callbacks**","metadata":{}},{"cell_type":"code","source":"# Save best model at every epoch\ncheckpoint = ModelCheckpoint(\n    'UNET_model',\n    monitor='val_loss',\n    verbose=1,\n    save_best_only=True,\n    save_weights_only=False,\n    mode='auto',\n)\n\n# Stop early if no improvement seen\nearly_stopping = EarlyStopping(\n    patience=5,\n    min_delta=0.0001,\n    restore_best_weights=True,\n)\n\n# Cosine decay\n'''\nlr_schedule = keras.optimizers.schedules.CosineDecay(\n    initial_learning_rate=2e-3,\n    decay_steps=EPOCHS + 2, \n    alpha=0,\n)\nlr_schedule = keras.callbacks.LearningRateScheduler(lr_schedule, verbose=0)\n'''\n\n# Reduce learning rate on plateau\nlr_plateau = keras.callbacks.ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    factor=0.1,\n    patience=5,\n    verbose=0,\n    min_delta=0.0001,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train model**","metadata":{}},{"cell_type":"code","source":"# Train model\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    callbacks=[checkpoint, \n               #early_stopping, \n               lr_plateau],\n    use_multiprocessing=False,\n    workers=4,\n    epochs=EPOCHS\n)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Learning curves**","metadata":{}},{"cell_type":"code","source":"# History\nhist_df = pd.DataFrame(history.history)\nhist_df.to_csv('history.csv')\n\n# PLOT TRAINING\nplt.figure(figsize=(15,5))\nplt.subplot(1,3,1)\nplt.plot(range(history.epoch[-1]+1),history.history['loss'],label='Train_Loss')\nplt.plot(range(history.epoch[-1]+1),history.history['val_loss'],label='Val_loss')\nplt.title('LOSS'); plt.xlabel('Epoch'); plt.ylabel('loss');plt.legend();\n\nplt.subplot(1,3,2)\nplt.plot(range(history.epoch[-1]+1),history.history['dice_coef'],label='Train_dice_coef')\nplt.plot(range(history.epoch[-1]+1),history.history['val_dice_coef'],label='Val_dice_coef')\nplt.title('DICE'); plt.xlabel('Epoch'); plt.ylabel('dice_coef');plt.legend(); \n\nplt.subplot(1,3,3)\nplt.plot(range(history.epoch[-1]+1),history.history['iou_coef'],label='Train_iou_coef')\nplt.plot(range(history.epoch[-1]+1),history.history['val_iou_coef'],label='Val_iou_coef')\nplt.title('IOU'); plt.xlabel('Epoch'); plt.ylabel('iou_coef');plt.legend();\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"markdown","source":"**Save model (if checkpoint not used)**","metadata":{}},{"cell_type":"code","source":"#save_model(model,'UNET_model')\n\n'''\ncustom_objects = custom_objects={\n    'dice_coef': dice_coef,\n    'iou_coef': iou_coef,\n    'bce_dice_loss': bce_dice_loss\n}\nmodel = load_model('./UNET_model', custom_objects=custom_objects)\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Preview predictions**","metadata":{}},{"cell_type":"code","source":"pred_batches = DataGenerator(X_valid.iloc[200:208,:], batch_size = 1, subset=\"train\", shuffle=False)\npreds = model.predict_generator(pred_batches,verbose=1)\n\nThreshold = 0.5\n# Visualizing\nfig = plt.figure(figsize=(10, 25))\ngs = gridspec.GridSpec(nrows=8, ncols=3)\ncolors = ['yellow','green','red']\nlabels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\npatches = [ mpatches.Patch(color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n\ncmap1 = mpl.colors.ListedColormap(colors[0])\ncmap2 = mpl.colors.ListedColormap(colors[1])\ncmap3= mpl.colors.ListedColormap(colors[2])\n\nfor i in range(8):\n    images, mask = pred_batches[i]\n    sample_img=images[0,:,:,0]\n    mask1=mask[0,:,:,0]\n    mask2=mask[0,:,:,1]\n    mask3=mask[0,:,:,2]\n    \n    pre=preds[i]\n    predict1=pre[:,:,0]\n    predict2=pre[:,:,1]\n    predict3=pre[:,:,2]\n    \n    predict1= (predict1 > Threshold).astype(np.float32)\n    predict2= (predict2 > Threshold).astype(np.float32)\n    predict3= (predict3 > Threshold).astype(np.float32)\n    \n    ax0 = fig.add_subplot(gs[i, 0])\n    im = ax0.imshow(sample_img, cmap='bone')\n    ax0.set_title(\"Image\", fontsize=12, y=1.01)\n    #--------------------------\n    ax1 = fig.add_subplot(gs[i, 1])\n    ax1.set_title(\"Mask\", fontsize=12,  y=1.01)\n    l0 = ax1.imshow(sample_img, cmap='bone')\n    l1 = ax1.imshow(np.ma.masked_where(mask1== False,  mask1),cmap=cmap1, alpha=1)\n    l2 = ax1.imshow(np.ma.masked_where(mask2== False,  mask2),cmap=cmap2, alpha=1)\n    l3 = ax1.imshow(np.ma.masked_where(mask3== False,  mask3),cmap=cmap3, alpha=1)\n    #--------------------------\n    ax2 = fig.add_subplot(gs[i, 2])\n    ax2.set_title(\"Predict\", fontsize=12, y=1.01)\n    l0 = ax2.imshow(sample_img, cmap='bone')\n    l1 = ax2.imshow(np.ma.masked_where(predict1== False,  predict1),cmap=cmap1, alpha=1)\n    l2 = ax2.imshow(np.ma.masked_where(predict2== False,  predict2),cmap=cmap2, alpha=1)\n    l3 = ax2.imshow(np.ma.masked_where(predict3== False,  predict3),cmap=cmap3, alpha=1)\n   \n\n    _ = [ax.set_axis_off() for ax in [ax0,ax1,ax2]]\n    colors = [im.cmap(im.norm(1)) for im in [l1,l2, l3]]\n    plt.legend(handles=patches, bbox_to_anchor=(1.1, 0.65), loc=2, borderaxespad=0.4,fontsize = 12,title='Mask Labels', title_fontsize=12, edgecolor=\"black\",  facecolor='#c5c6c7')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test set predictions","metadata":{}},{"cell_type":"markdown","source":"**Make predictions on test set**","metadata":{}},{"cell_type":"code","source":"#gcd(80,144)=16=BATCH_SIZE\npred_batches = DataGenerator(test_df, batch_size = BATCH_SIZE, subset=\"test\", shuffle=False)\nnum_batches = int(len(test_df)/BATCH_SIZE)\n\nfor i in range(num_batches):\n    # Predict\n    preds = model.predict(pred_batches[i],verbose=0)     # shape: (16,im_height,im_width,3)\n    \n    # Rle encode\n    for j in range(BATCH_SIZE):\n        for k in range(3):\n            pred_img = cv2.resize(preds[j,:,:,k], (test_df.loc[i*BATCH_SIZE+j,\"width\"], test_df.loc[i*BATCH_SIZE+j,\"height\"]), interpolation=cv2.INTER_NEAREST) # resize probabilities to original shape\n            pred_img = (pred_img>0.5).astype(dtype='uint8')    # classify\n            submission.loc[3*(i*BATCH_SIZE+j)+k,'predicted'] = rle_encode(pred_img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Save predictions**","metadata":{}},{"cell_type":"code","source":"submission.to_csv('submission.csv',index=False)\nsubmission.sample(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}