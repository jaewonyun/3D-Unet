{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"In this notebook, we perform **GI tract semantic image segmentation** using U-Net. ","metadata":{}},{"cell_type":"markdown","source":"* Part 1: [UWMGI Segmentation - UNet, keras [Train]](https://www.kaggle.com/code/samuelcortinhas/uwmgi-segmentation-unet-keras-train) \n* Part 2: [UWMGI Segmentation - UNet, keras [Inference]](https://www.kaggle.com/code/samuelcortinhas/uwmgi-segmentation-unet-keras-inference)\n* Trained weights: [UWMGI - Trained UNet model](https://www.kaggle.com/datasets/samuelcortinhas/uwmgi-trained-unet-model)","metadata":{}},{"cell_type":"markdown","source":"**Libraries**","metadata":{}},{"cell_type":"code","source":"# Core\nimport pandas as pd\nimport numpy as np\nimport os\nimport cv2\nimport gc\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm\nfrom datetime import datetime\nimport json,itertools\nfrom typing import Optional\nfrom glob import glob\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.gridspec as gridspec\nimport matplotlib.patches as mpatches\nimport matplotlib as mpl\nfrom sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\nimport random\n\n# Keras\nfrom tensorflow import keras\nimport tensorflow as tf\nimport keras\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.losses import binary_crossentropy\nfrom keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\nfrom keras.models import load_model, save_model","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-16T12:01:23.278664Z","iopub.execute_input":"2022-06-16T12:01:23.279176Z","iopub.status.idle":"2022-06-16T12:01:31.538945Z","shell.execute_reply.started":"2022-06-16T12:01:23.279051Z","shell.execute_reply":"2022-06-16T12:01:31.53795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reproducibility**","metadata":{}},{"cell_type":"code","source":"# Set random seeds\ndef set_seed(seed=0):\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\nset_seed()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:01:41.187336Z","iopub.execute_input":"2022-06-16T12:01:41.188513Z","iopub.status.idle":"2022-06-16T12:01:41.193438Z","shell.execute_reply.started":"2022-06-16T12:01:41.188452Z","shell.execute_reply":"2022-06-16T12:01:41.192576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Config**","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 16\nEPOCHS = 40\nn_splits = 5\nfold_selected = 2   # 1,...,5\nim_width = 320\nim_height = 320","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:01:42.912242Z","iopub.execute_input":"2022-06-16T12:01:42.912567Z","iopub.status.idle":"2022-06-16T12:01:42.916628Z","shell.execute_reply.started":"2022-06-16T12:01:42.912534Z","shell.execute_reply":"2022-06-16T12:01:42.915737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"markdown","source":"**Train set**","metadata":{}},{"cell_type":"code","source":"# Train set\ntrain_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')\nprint(train_df.shape)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:01:44.51493Z","iopub.execute_input":"2022-06-16T12:01:44.515467Z","iopub.status.idle":"2022-06-16T12:01:45.184569Z","shell.execute_reply.started":"2022-06-16T12:01:44.515428Z","shell.execute_reply":"2022-06-16T12:01:45.183555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Test set**","metadata":{}},{"cell_type":"markdown","source":"*Note:* This is a code competition, which means the 'real' test set will be populated at inference time.","metadata":{}},{"cell_type":"code","source":"# Test set\ntest_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\n\nif len(test_df)==0:\n    DEBUG=True\n    test_df = train_df.iloc[:10*16*3,:]\n    test_df[\"segmentation\"]=''\n    test_df=test_df.rename(columns={\"segmentation\":\"predicted\"})\nelse:\n    DEBUG=False\n\nsubmission=test_df.copy()\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:01:50.008618Z","iopub.execute_input":"2022-06-16T12:01:50.009695Z","iopub.status.idle":"2022-06-16T12:01:50.038728Z","shell.execute_reply.started":"2022-06-16T12:01:50.009653Z","shell.execute_reply":"2022-06-16T12:01:50.037862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"**Metadata**","metadata":{}},{"cell_type":"code","source":"# Metadata\ndef preprocessing(df, subset=\"train\"):\n    #--------------------------------------------------------------------------\n    df[\"case\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\")[0].replace(\"case\", \"\")))\n    df[\"day\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\")[1].replace(\"day\", \"\")))\n    df[\"slice\"] = df[\"id\"].apply(lambda x: x.split(\"_\")[3])\n    #--------------------------------------------------------------------------\n    if (subset==\"train\") or (DEBUG):\n        DIR=\"../input/uw-madison-gi-tract-image-segmentation/train\"\n    else:\n        DIR=\"../input/uw-madison-gi-tract-image-segmentation/test\"\n    \n    all_images = glob(os.path.join(DIR, \"**\", \"*.png\"), recursive=True)\n    x = all_images[0].rsplit(\"/\", 4)[0] ## ../input/uw-madison-gi-tract-image-segmentation/train\n\n    path_partial_list = []\n    for i in range(0, df.shape[0]):\n        path_partial_list.append(os.path.join(x,\n                              \"case\"+str(df[\"case\"].values[i]),\n                              \"case\"+str(df[\"case\"].values[i])+\"_\"+ \"day\"+str(df[\"day\"].values[i]),\n                              \"scans\",\n                              \"slice_\"+str(df[\"slice\"].values[i])))\n    df[\"path_partial\"] = path_partial_list\n    #--------------------------------------------------------------------------\n    path_partial_list = []\n    for i in range(0, len(all_images)):\n        path_partial_list.append(str(all_images[i].rsplit(\"_\",4)[0]))\n\n    tmp_df = pd.DataFrame()\n    tmp_df['path_partial'] = path_partial_list\n    tmp_df['path'] = all_images\n\n    #--------------------------------------------------------------------------\n    df = df.merge(tmp_df, on=\"path_partial\").drop(columns=[\"path_partial\"])\n    #--------------------------------------------------------------------------\n    df[\"width\"] = df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[1]))\n    df[\"height\"] = df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[2]))\n    #--------------------------------------------------------------------------\n    del x, path_partial_list, tmp_df\n    #--------------------------------------------------------------------------\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:04:42.649315Z","iopub.execute_input":"2022-06-16T12:04:42.649703Z","iopub.status.idle":"2022-06-16T12:04:42.669925Z","shell.execute_reply.started":"2022-06-16T12:04:42.64966Z","shell.execute_reply":"2022-06-16T12:04:42.669254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = preprocessing(train_df, subset=\"train\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:04:42.903032Z","iopub.execute_input":"2022-06-16T12:04:42.903775Z","iopub.status.idle":"2022-06-16T12:04:51.136694Z","shell.execute_reply.started":"2022-06-16T12:04:42.903739Z","shell.execute_reply":"2022-06-16T12:04:51.135781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df=preprocessing(test_df, subset=\"test\")\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:04:51.138346Z","iopub.execute_input":"2022-06-16T12:04:51.13858Z","iopub.status.idle":"2022-06-16T12:04:52.083506Z","shell.execute_reply.started":"2022-06-16T12:04:51.138551Z","shell.execute_reply":"2022-06-16T12:04:52.081445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Restructure df**","metadata":{}},{"cell_type":"code","source":"# Restructure\ndef restructure(df, subset=\"train\"):\n    # RESTRUCTURE  DATAFRAME\n    df_out = pd.DataFrame({'id': df['id'][::3]})\n\n    if subset==\"train\":\n        df_out['large_bowel'] = df['segmentation'][::3].values\n        df_out['small_bowel'] = df['segmentation'][1::3].values\n        df_out['stomach'] = df['segmentation'][2::3].values\n\n    df_out['path'] = df['path'][::3].values\n    df_out['case'] = df['case'][::3].values\n    df_out['day'] = df['day'][::3].values\n    df_out['slice'] = df['slice'][::3].values\n    df_out['width'] = df['width'][::3].values\n    df_out['height'] = df['height'][::3].values\n\n    df_out=df_out.reset_index(drop=True)\n    df_out=df_out.fillna('')\n    if subset==\"train\":\n        df_out['count'] = np.sum(df_out.iloc[:,1:4]!='',axis=1).values\n    \n    return df_out","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:04:52.085167Z","iopub.execute_input":"2022-06-16T12:04:52.085465Z","iopub.status.idle":"2022-06-16T12:04:52.095167Z","shell.execute_reply.started":"2022-06-16T12:04:52.085425Z","shell.execute_reply":"2022-06-16T12:04:52.094336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=restructure(train_df, subset=\"train\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:04:52.097451Z","iopub.execute_input":"2022-06-16T12:04:52.097959Z","iopub.status.idle":"2022-06-16T12:04:52.202229Z","shell.execute_reply.started":"2022-06-16T12:04:52.097915Z","shell.execute_reply":"2022-06-16T12:04:52.201319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df=restructure(test_df, subset=\"test\")\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:04:52.203879Z","iopub.execute_input":"2022-06-16T12:04:52.204186Z","iopub.status.idle":"2022-06-16T12:04:52.222915Z","shell.execute_reply.started":"2022-06-16T12:04:52.204143Z","shell.execute_reply":"2022-06-16T12:04:52.222009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Remove mislabelled data**","metadata":{}},{"cell_type":"code","source":"# Remove mislabeled training data\ntrain_df = train_df[(train_df['case']!=7)|(train_df['day']!=0)].reset_index(drop=True)\ntrain_df = train_df[(train_df['case']!=81)|(train_df['day']!=30)].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:04:52.224389Z","iopub.execute_input":"2022-06-16T12:04:52.224688Z","iopub.status.idle":"2022-06-16T12:04:52.277663Z","shell.execute_reply.started":"2022-06-16T12:04:52.224646Z","shell.execute_reply":"2022-06-16T12:04:52.276861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Garbage collection\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:04:52.279275Z","iopub.execute_input":"2022-06-16T12:04:52.27959Z","iopub.status.idle":"2022-06-16T12:04:52.530649Z","shell.execute_reply.started":"2022-06-16T12:04:52.279549Z","shell.execute_reply":"2022-06-16T12:04:52.529554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions","metadata":{}},{"cell_type":"markdown","source":"**RLE encoding**","metadata":{}},{"cell_type":"code","source":"# Run-length encoding\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle_decode(mask_rle, shape, color=1):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros((shape[0] * shape[1], shape[2]), dtype=np.float32)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n    return img.reshape(shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:05:57.937248Z","iopub.execute_input":"2022-06-16T12:05:57.937594Z","iopub.status.idle":"2022-06-16T12:05:57.948966Z","shell.execute_reply.started":"2022-06-16T12:05:57.937561Z","shell.execute_reply":"2022-06-16T12:05:57.947997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Metrics**","metadata":{}},{"cell_type":"code","source":"# Metrics\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef iou_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n    return iou\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(tf.cast(y_true, tf.float32), y_pred) + dice_loss(tf.cast(y_true, tf.float32), y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:05:58.492659Z","iopub.execute_input":"2022-06-16T12:05:58.493032Z","iopub.status.idle":"2022-06-16T12:05:58.504962Z","shell.execute_reply.started":"2022-06-16T12:05:58.492992Z","shell.execute_reply":"2022-06-16T12:05:58.50391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data generator**","metadata":{}},{"cell_type":"code","source":"# Images reshaped to (im_height,im_width)\nclass DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, df, batch_size = BATCH_SIZE, subset=\"train\", shuffle=False):\n        super().__init__()\n        self.df = df\n        self.shuffle = shuffle\n        self.subset = subset\n        self.batch_size = batch_size\n        self.indexes = np.arange(len(df))\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.floor(len(self.df) / self.batch_size))\n    \n    def on_epoch_end(self):\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    def __getitem__(self, index):\n        X = np.empty((self.batch_size,im_height,im_width,3))\n        y = np.empty((self.batch_size,im_height,im_width,3))\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        for i, img_path in enumerate(self.df['path'].iloc[indexes]):\n            w=self.df['width'].iloc[indexes[i]]\n            h=self.df['height'].iloc[indexes[i]]\n            img = self.__load_grayscale(img_path)  # shape: (im_height,im_width,1)\n            X[i,] = img   # broadcast to shape: (im_height,im_width,3)\n            if self.subset == 'train':\n                for k,j in enumerate([\"large_bowel\",\"small_bowel\",\"stomach\"]):\n                    rles = self.df[j].iloc[indexes[i]]\n                    mask = rle_decode(rles, shape=(h, w, 1))\n                    mask = cv2.resize(mask, (im_height,im_width))\n                    y[i,:,:,k] = mask\n        if self.subset == 'train':\n            return X, y\n        else: \n            return X\n        \n        # To do: add data augmentation\n        \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)\n        dsize = (im_height,im_width)\n        img = cv2.resize(img, dsize)\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n        return img","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:05:59.221101Z","iopub.execute_input":"2022-06-16T12:05:59.221458Z","iopub.status.idle":"2022-06-16T12:05:59.699185Z","shell.execute_reply.started":"2022-06-16T12:05:59.221426Z","shell.execute_reply":"2022-06-16T12:05:59.698148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"**Target distribution**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,4))\nbar = plt.bar([1,2,3],100*np.mean(train_df.iloc[:,1:4]!='',axis=0))\nplt.title('Percent Training Images with Mask', fontsize=16)\nplt.ylabel('Percent of Images'); plt.xlabel('Class Type')\nplt.xticks([1,2,3])\nlabels=[\"large bowel\",\"small bowel\",\"stomach\"]\nfor rect, lbl in zip(bar, labels):\n    height = rect.get_height()\n    plt.text(rect.get_x() + rect.get_width()/3, height,  lbl,\n             ha='center', va='bottom',fontsize=16)\n    plt.text(rect.get_x() + rect.get_width()/1.3, height, '%.1f %%' % height,\n             ha='center', va='bottom',fontsize=13)\n\nplt.ylim((0,50))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:06:06.214755Z","iopub.execute_input":"2022-06-16T12:06:06.215652Z","iopub.status.idle":"2022-06-16T12:06:06.459658Z","shell.execute_reply.started":"2022-06-16T12:06:06.215606Z","shell.execute_reply":"2022-06-16T12:06:06.4589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Preview some samples**","metadata":{}},{"cell_type":"code","source":"# SAMPLES\nMasks = list(train_df[train_df['large_bowel']!=''].sample(BATCH_SIZE).index)\nMasks += list(train_df[train_df['small_bowel']!=''].sample(BATCH_SIZE*2).index)\nMasks += list(train_df[train_df['stomach']!=''].sample(BATCH_SIZE*3).index)\n\n# DATA GENERATOR\nView_batches = DataGenerator(train_df[train_df.index.isin(Masks)],shuffle=True)\n\n# Visualizing\nfig = plt.figure(figsize=(10, 25))\ngs = gridspec.GridSpec(nrows=6, ncols=2)\ncolors = ['yellow','green','red']\nlabels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\npatches = [ mpatches.Patch(color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n\ncmap1 = mpl.colors.ListedColormap(colors[0])\ncmap2 = mpl.colors.ListedColormap(colors[1])\ncmap3= mpl.colors.ListedColormap(colors[2])\n\nfor i in range(6):\n    images, mask = View_batches[i]\n    sample_img=images[0,:,:,0]\n    mask1=mask[0,:,:,0]\n    mask2=mask[0,:,:,1]\n    mask3=mask[0,:,:,2]\n    \n    ax0 = fig.add_subplot(gs[i, 0])\n    im = ax0.imshow(sample_img, cmap='bone')\n\n    ax1 = fig.add_subplot(gs[i, 1])\n    if i==0:\n        ax0.set_title(\"Image\", fontsize=15, weight='bold', y=1.02)\n        ax1.set_title(\"Mask\", fontsize=15, weight='bold', y=1.02)\n        plt.legend(handles=patches, bbox_to_anchor=(1.1, 0.65), loc=2, borderaxespad=0.4,fontsize = 14,title='Mask Labels', title_fontsize=14, edgecolor=\"black\",  facecolor='#c5c6c7')\n\n    l0 = ax1.imshow(sample_img, cmap='bone')\n    l1 = ax1.imshow(np.ma.masked_where(mask1== False,  mask1),cmap=cmap1, alpha=1)\n    l2 = ax1.imshow(np.ma.masked_where(mask2== False,  mask2),cmap=cmap2, alpha=1)\n    l3 = ax1.imshow(np.ma.masked_where(mask3== False,  mask3),cmap=cmap3, alpha=1)\n    _ = [ax.set_axis_off() for ax in [ax0,ax1]]\n\n    colors = [im.cmap(im.norm(1)) for im in [l1,l2, l3]]","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:06:33.551537Z","iopub.execute_input":"2022-06-16T12:06:33.551886Z","iopub.status.idle":"2022-06-16T12:06:36.012001Z","shell.execute_reply.started":"2022-06-16T12:06:33.551846Z","shell.execute_reply":"2022-06-16T12:06:36.011148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross-validation","metadata":{}},{"cell_type":"markdown","source":"**Group k-fold**","metadata":{}},{"cell_type":"code","source":"# Group by case id\nskf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)\nfor fold, (_, val_idx) in enumerate(skf.split(X=train_df, y=train_df['count'], groups=train_df['case']), 1):\n    train_df.loc[val_idx, 'fold'] = fold\n\ntrain_df['fold'] = train_df['fold'].astype(np.uint8)\n\ntrain_ids = train_df[train_df[\"fold\"]!=fold_selected].index\nvalid_ids = train_df[train_df[\"fold\"]==fold_selected].index\n\nX_train = train_df[train_df.index.isin(train_ids)]\nX_valid = train_df[train_df.index.isin(valid_ids)]\n\ntrain_df.groupby('fold').size()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:07:29.318166Z","iopub.execute_input":"2022-06-16T12:07:29.318492Z","iopub.status.idle":"2022-06-16T12:07:29.536247Z","shell.execute_reply.started":"2022-06-16T12:07:29.318458Z","shell.execute_reply":"2022-06-16T12:07:29.535334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fold sizes\ntrain_df.groupby(['fold','count'])['id'].count()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:07:39.06083Z","iopub.execute_input":"2022-06-16T12:07:39.061155Z","iopub.status.idle":"2022-06-16T12:07:39.080163Z","shell.execute_reply.started":"2022-06-16T12:07:39.061122Z","shell.execute_reply":"2022-06-16T12:07:39.079574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Debugging**","metadata":{}},{"cell_type":"code","source":"# Check submission format works\nexperimental=False\nif experimental:\n    X_train=X_train[X_train.case.isin(X_train.case.unique()[:5])]       # take first few cases\n    X_valid=X_valid[X_valid.case.isin(X_valid.case.unique()[:2])]       # take first few cases\n    \nprint('X_train shape:', X_train.shape)\nprint('X_valid shape:', X_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:09:22.033095Z","iopub.execute_input":"2022-06-16T12:09:22.033424Z","iopub.status.idle":"2022-06-16T12:09:22.041559Z","shell.execute_reply.started":"2022-06-16T12:09:22.033392Z","shell.execute_reply":"2022-06-16T12:09:22.040677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Define generator**","metadata":{}},{"cell_type":"code","source":"train_generator = DataGenerator(X_train, shuffle=True)\nval_generator = DataGenerator(X_valid)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:09:34.432285Z","iopub.execute_input":"2022-06-16T12:09:34.432632Z","iopub.status.idle":"2022-06-16T12:09:34.4388Z","shell.execute_reply.started":"2022-06-16T12:09:34.432595Z","shell.execute_reply":"2022-06-16T12:09:34.437854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# U-Net model","metadata":{}},{"cell_type":"markdown","source":"**Download U-Net**","metadata":{}},{"cell_type":"code","source":"! pip install segmentation-models","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-16T12:15:29.4576Z","iopub.execute_input":"2022-06-16T12:15:29.458625Z","iopub.status.idle":"2022-06-16T12:15:42.979712Z","shell.execute_reply.started":"2022-06-16T12:15:29.458573Z","shell.execute_reply":"2022-06-16T12:15:42.97875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install git+https://github.com/qubvel/segmentation_models","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-16T12:15:42.983509Z","iopub.execute_input":"2022-06-16T12:15:42.983951Z","iopub.status.idle":"2022-06-16T12:15:56.657751Z","shell.execute_reply.started":"2022-06-16T12:15:42.98388Z","shell.execute_reply":"2022-06-16T12:15:56.656537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models as sm\nsm.set_framework('tf.keras')\nsm.framework()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:15:56.660296Z","iopub.execute_input":"2022-06-16T12:15:56.660697Z","iopub.status.idle":"2022-06-16T12:15:56.950925Z","shell.execute_reply.started":"2022-06-16T12:15:56.660638Z","shell.execute_reply":"2022-06-16T12:15:56.950107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Define model**","metadata":{}},{"cell_type":"code","source":"from segmentation_models import Unet\nfrom segmentation_models.utils import set_trainable\n\nmodel = Unet('resnet34',input_shape=(im_height, im_width, 3), classes=3, activation='sigmoid', encoder_weights='imagenet')\nmodel.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef,iou_coef])","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-16T12:16:17.711173Z","iopub.execute_input":"2022-06-16T12:16:17.711531Z","iopub.status.idle":"2022-06-16T12:16:24.128245Z","shell.execute_reply.started":"2022-06-16T12:16:17.711496Z","shell.execute_reply":"2022-06-16T12:16:24.127508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:16:33.489274Z","iopub.execute_input":"2022-06-16T12:16:33.489681Z","iopub.status.idle":"2022-06-16T12:16:33.667363Z","shell.execute_reply.started":"2022-06-16T12:16:33.489633Z","shell.execute_reply":"2022-06-16T12:16:33.666408Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training model","metadata":{}},{"cell_type":"markdown","source":"**Callbacks**","metadata":{}},{"cell_type":"code","source":"# Save best model at every epoch\ncheckpoint = ModelCheckpoint(\n    'UNET_model',\n    monitor='val_loss',\n    verbose=1,\n    save_best_only=True,\n    save_weights_only=False,\n    mode='auto',\n)\n\n# Stop early if no improvement seen\nearly_stopping = EarlyStopping(\n    patience=5,\n    min_delta=0.0001,\n    restore_best_weights=True,\n)\n\n# Cosine decay\n'''\nlr_schedule = keras.optimizers.schedules.CosineDecay(\n    initial_learning_rate=2e-3,\n    decay_steps=EPOCHS + 2, \n    alpha=0,\n)\nlr_schedule = keras.callbacks.LearningRateScheduler(lr_schedule, verbose=0)\n'''\n\n# Reduce learning rate on plateau\nlr_plateau = keras.callbacks.ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    factor=0.1,\n    patience=5,\n    verbose=0,\n    min_delta=0.0001,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train model**","metadata":{}},{"cell_type":"code","source":"# Train model\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    callbacks=[checkpoint, \n               #early_stopping, \n               lr_plateau],\n    use_multiprocessing=False,\n    workers=4,\n    epochs=EPOCHS\n)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Learning curves**","metadata":{}},{"cell_type":"code","source":"# History\nhist_df = pd.DataFrame(history.history)\nhist_df.to_csv('history.csv')\n\n# PLOT TRAINING\nplt.figure(figsize=(15,5))\nplt.subplot(1,3,1)\nplt.plot(range(history.epoch[-1]+1),history.history['loss'],label='Train_Loss')\nplt.plot(range(history.epoch[-1]+1),history.history['val_loss'],label='Val_loss')\nplt.title('LOSS'); plt.xlabel('Epoch'); plt.ylabel('loss');plt.legend();\n\nplt.subplot(1,3,2)\nplt.plot(range(history.epoch[-1]+1),history.history['dice_coef'],label='Train_dice_coef')\nplt.plot(range(history.epoch[-1]+1),history.history['val_dice_coef'],label='Val_dice_coef')\nplt.title('DICE'); plt.xlabel('Epoch'); plt.ylabel('dice_coef');plt.legend(); \n\nplt.subplot(1,3,3)\nplt.plot(range(history.epoch[-1]+1),history.history['iou_coef'],label='Train_iou_coef')\nplt.plot(range(history.epoch[-1]+1),history.history['val_iou_coef'],label='Val_iou_coef')\nplt.title('IOU'); plt.xlabel('Epoch'); plt.ylabel('iou_coef');plt.legend();\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"markdown","source":"**Save model (if checkpoint not used)**","metadata":{}},{"cell_type":"code","source":"#save_model(model,'UNET_model')\n\n'''\ncustom_objects = custom_objects={\n    'dice_coef': dice_coef,\n    'iou_coef': iou_coef,\n    'bce_dice_loss': bce_dice_loss\n}\nmodel = load_model('./UNET_model', custom_objects=custom_objects)\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Preview predictions**","metadata":{}},{"cell_type":"code","source":"pred_batches = DataGenerator(X_valid.iloc[200:208,:], batch_size = 1, subset=\"train\", shuffle=False)\npreds = model.predict_generator(pred_batches,verbose=1)\n\nThreshold = 0.5\n# Visualizing\nfig = plt.figure(figsize=(10, 25))\ngs = gridspec.GridSpec(nrows=8, ncols=3)\ncolors = ['yellow','green','red']\nlabels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\npatches = [ mpatches.Patch(color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n\ncmap1 = mpl.colors.ListedColormap(colors[0])\ncmap2 = mpl.colors.ListedColormap(colors[1])\ncmap3= mpl.colors.ListedColormap(colors[2])\n\nfor i in range(8):\n    images, mask = pred_batches[i]\n    sample_img=images[0,:,:,0]\n    mask1=mask[0,:,:,0]\n    mask2=mask[0,:,:,1]\n    mask3=mask[0,:,:,2]\n    \n    pre=preds[i]\n    predict1=pre[:,:,0]\n    predict2=pre[:,:,1]\n    predict3=pre[:,:,2]\n    \n    predict1= (predict1 > Threshold).astype(np.float32)\n    predict2= (predict2 > Threshold).astype(np.float32)\n    predict3= (predict3 > Threshold).astype(np.float32)\n    \n    ax0 = fig.add_subplot(gs[i, 0])\n    im = ax0.imshow(sample_img, cmap='bone')\n    ax0.set_title(\"Image\", fontsize=12, y=1.01)\n    #--------------------------\n    ax1 = fig.add_subplot(gs[i, 1])\n    ax1.set_title(\"Mask\", fontsize=12,  y=1.01)\n    l0 = ax1.imshow(sample_img, cmap='bone')\n    l1 = ax1.imshow(np.ma.masked_where(mask1== False,  mask1),cmap=cmap1, alpha=1)\n    l2 = ax1.imshow(np.ma.masked_where(mask2== False,  mask2),cmap=cmap2, alpha=1)\n    l3 = ax1.imshow(np.ma.masked_where(mask3== False,  mask3),cmap=cmap3, alpha=1)\n    #--------------------------\n    ax2 = fig.add_subplot(gs[i, 2])\n    ax2.set_title(\"Predict\", fontsize=12, y=1.01)\n    l0 = ax2.imshow(sample_img, cmap='bone')\n    l1 = ax2.imshow(np.ma.masked_where(predict1== False,  predict1),cmap=cmap1, alpha=1)\n    l2 = ax2.imshow(np.ma.masked_where(predict2== False,  predict2),cmap=cmap2, alpha=1)\n    l3 = ax2.imshow(np.ma.masked_where(predict3== False,  predict3),cmap=cmap3, alpha=1)\n   \n\n    _ = [ax.set_axis_off() for ax in [ax0,ax1,ax2]]\n    colors = [im.cmap(im.norm(1)) for im in [l1,l2, l3]]\n    plt.legend(handles=patches, bbox_to_anchor=(1.1, 0.65), loc=2, borderaxespad=0.4,fontsize = 12,title='Mask Labels', title_fontsize=12, edgecolor=\"black\",  facecolor='#c5c6c7')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test set predictions","metadata":{}},{"cell_type":"markdown","source":"**Make predictions on test set**","metadata":{}},{"cell_type":"code","source":"#gcd(80,144)=16=BATCH_SIZE\npred_batches = DataGenerator(test_df, batch_size = BATCH_SIZE, subset=\"test\", shuffle=False)\nnum_batches = int(len(test_df)/BATCH_SIZE)\n\nfor i in range(num_batches):\n    # Predict\n    preds = model.predict(pred_batches[i],verbose=0)     # shape: (16,im_height,im_width,3)\n    \n    # Rle encode\n    for j in range(BATCH_SIZE):\n        for k in range(3):\n            pred_img = cv2.resize(preds[j,:,:,k], (test_df.loc[i*BATCH_SIZE+j,\"width\"], test_df.loc[i*BATCH_SIZE+j,\"height\"]), interpolation=cv2.INTER_NEAREST) # resize probabilities to original shape\n            pred_img = (pred_img>0.5).astype(dtype='uint8')    # classify\n            submission.loc[3*(i*BATCH_SIZE+j)+k,'predicted'] = rle_encode(pred_img)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Save predictions**","metadata":{}},{"cell_type":"code","source":"submission.to_csv('submission.csv',index=False)\nsubmission.sample(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Acknowledgements:**\n* [UWM - GI Tract Image Segmentation - EDA](https://www.kaggle.com/code/dschettler8845/uwm-gi-tract-image-segmentation-eda) by [Darien Schettler](https://www.kaggle.com/dschettler8845).\n* [UWMGI: UNet Keras [Train] with EDA](https://www.kaggle.com/code/ammarnassanalhajali/uwmgi-unet-keras-train-with-eda) by [Ammar Alhaj Ali\n](https://www.kaggle.com/ammarnassanalhajali).","metadata":{}}]}